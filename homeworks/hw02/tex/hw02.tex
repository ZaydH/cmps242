\documentclass{report}

\usepackage{fullpage}
\usepackage[skip=4pt]{caption} % ``skip'' sets the spacing between the figure and the caption.
\usepackage{pgfplots}   % Needed for plotting
\usepackage{amsmath}    % Allows for piecewise functions using the ``cases'' construct
%\usepackage{mathrsfs}   % Use the ``\mathscr'' command in an equation.

\usepackage[obeyspaces,spaces]{url} % Used for typesetting with the ``path'' command
\usepackage[hidelinks]{hyperref}   % Make the cross references clickable hyperlinks
\usepackage[bottom]{footmisc} % Prevents the table going below the footnote
\usepackage{nccmath}    % Needed in the workaround for the ``aligncustom'' environment
\usepackage{amssymb}    % Used for black QED symbol   
\usepackage{bm}    % Allows for bolding math symbols.

\usepackage{tabto}     % Allows to tab to certain point on a line

\newcommand{\hangindentdistance}{1cm}
\setlength{\parindent}{0pt}
\setlength{\leftskip}{\hangindentdistance}
\setlength{\hangafter}{1}


% Set up page formatting
\usepackage{fancyhdr} % Used for every page footer and title.
\pagestyle{fancy}
\fancyhf{} % Clears both the header and footer
\renewcommand{\headrulewidth}{0pt} % Eliminates line at the top of the page.
\fancyfoot[LO]{CMPS242 \textendash{} Homework \#2} % Left
\fancyfoot[CO]{\thepage} % Center
\fancyfoot[RO]{Zayd Hammoudeh} %Right

% Change interline spacing.
\renewcommand{\baselinestretch}{1.1}
\newenvironment{aligncustom}
{ \csname align*\endcsname % Need to do this instead of \begin{align*} because of LaTeX bug.
    \centering
}
{
  \csname endalign*\endcsname
}
%--------------------------------------------------


\title{\textbf{CMPS242 Homework \#2 -- Chapter \#1 Exercises}}
\author{Zayd Hammoudeh}

%---------------------------------------------------%
% Define the Environments for the Problem Inclusion %
%---------------------------------------------------%
\newcounter{subProbCount}       % Initialize the subproblem counter
\newcounter{extraProbCount}     % Initialize the special problem counter
\setcounter{extraProbCount}{0}  % Set it to zero.  It is incremented in the ``extraproblem'' environment.
\newenvironment{problemshell}{
  \par%
  \medskip
  \leftskip=0pt\rightskip=0pt%
}
{
  \par\medskip
  \setcounter{subProbCount}{1} % Reset the subproblem counter
}
\newenvironment{extraproblem}{
  \stepcounter{extraProbCount} % Increment the subproblem counter
  \begin{problemshell}
    \noindent \textit{Extra Problem \#\arabic{extraProbCount}} \\
    \bfseries
}
{
  \end{problemshell}
}
\newenvironment{problem}[2]
{%
  \begin{problemshell}
    \noindent \textit{Chapter \##1, Problem \##2} \\
    \bfseries  
}
{
  \end{problemshell}
}
\newenvironment{subproblem}
{%
  \par%
  \medskip
  \leftskip=0pt\rightskip=0pt%
  \bfseries  
  % Print the subproblem count and offset to the left
  (\alph{subProbCount}) \hangindent=\hangindentdistance \hangafter=1 \tabto{\hangindentdistance}
}
{
  \stepcounter{subProbCount} % Increment the subproblem counter
  \par\medskip
}
\newcommand{\KL}{\textrm{KL}}

%\newcommand{\problem}[3]{\noindent \textit{Chapter \##1, Problem \##2}
%  \\
%  \textbf{#3}  \\ }
%
%
%\newcommand{\subproblem}[2]{~\\ (#1) \hangindent=\hangindentdistance \hangafter=2 \tabto{\hangindentdistance} \textbf{#2}~\\}

\begin{document}
  \maketitle
  
  \begin{problem}{1}{3}
    Suppose that we have three colored boxes, $r$~(red), $b$~(blue), and $g$~(green).  Box~$r$ contains $3$~apples, $4$~oranges, and $3$~limes; box$~b$ contains $1$~apple, $1$~orange, and $0$~limes; box~$g$ contains $3$~apples, $3$~oranges, and $4$~limes.
  \end{problem}
  
  \begin{subproblem}
    If a box is chosen at random with probabilities, $p(r)=0.2$, $p(b)=0.2$, and~$p(g)=0.6$, and a piece of fruit is removed from the box (with equal probability of selecting any of the items in the box), then what is the probability of selecting an apple?
  \end{subproblem}

  Recall the Law of Total Probability establishes that given a set of disjoint events,~$B_1,...B_n$, that partition the sample space,~$S$, (i.e.,~$\bigcup_{i=1}^{n}B_i=S$ and~$\forall_{i,j} B_i \cap B_j = \emptyset$), then for any event~$A$ in~$S$:
  
  \[ \Pr[A] = \sum_{i=1}^{n} \Pr[B_i] * \Pr[A | B_i] \]
  
  Hence, define~$B$ as the set of all boxes (i.e.,~red, blue, and green) where $b_i \in B$.  Then, the probability of selecting an apple can be found via:
  
  \[\Pr[apple]=\sum_{b_i \in B}\Pr[apple|b_{i}]*\Pr[b_i]\textrm{.}\]
  
  This can be rewritten as:
  
  \begin{aligncustom}
    \Pr[apple] &= \Pr[apple|r]*\Pr[r] + \Pr[apple|b]*\Pr[b] + \Pr[apple|g]*\Pr[g] \\
    \Pr[apple] &= 0.3*0.2 + 0.5*0.2 + 0.3*0.6 \\
    \Pr[apple] &= \boxed{0.34}
  \end{aligncustom}

  \begin{subproblem}
    If we observe that the selected fruit is in fact an orange, what is the probability that it came from the green box?
  \end{subproblem}
  
  The goal of this question is to find the posterior probability,~$\Pr[g|orange]$.  The simplest way to do that is to use the priors,~$\Pr[orange]$ and~$\Pr[g]$ with the likelihood,~$\Pr[orange|g]$.  Hence:

  \begin{equation}
    \Pr[g|orange]=\frac{\Pr[orange|g]*\Pr[g]}{\Pr[orange]}\textrm{.}
    \label{eq:orangeBayes}
  \end{equation}
  
  Using again the Law of Total Probability, the prior probability of selecting an zzzorange,~$\Pr[o]$, is:
  
  \begin{aligncustom}
    \Pr[orange] &= \Pr[orange|r]*\Pr[r] + \Pr[orange|b]*\Pr[b] + \Pr[orange|g]*\Pr[g] \\
    \Pr[orange] &= 0.4*0.2 + 0.5*0.2 + 0.3*0.6 \\
    \Pr[orange] &= 0.36
  \end{aligncustom}

  This can then be substituted into the Eq.~\eqref{eq:orangeBayes}.
  
  \begin{aligncustom}
    \Pr[g|orange] &= \frac{\Pr[orange|g]*\Pr[g]}{\Pr[orange]} \\
    \Pr[g|orange] &= \frac{0.3*0.6}{0.36} \\
    \Pr[g|orange] &= \boxed{0.5}
  \end{aligncustom}



  %---------------------------------------------------%
  \newpage
  \begin{problem}{1}{9}
    Show that the mode (i.e.,~the maximum) of the Gaussian distribution~(1.46) is given by~$\mu$.  Similarly, show that the mode of the multivariate Gaussian~(1.52) is given by~$\mathbf{\mu}$.
  \end{problem}
  
  \begin{subproblem}
    Show the maximum of the Gaussian distribution is given by~$\mu$.
  \end{subproblem}
  
  The maximizing value of a strictly positive function is equal to the maximizing value of the logarithm of the function.  Below, ``$\ln$''~is applied to the Gaussian formula.
  
  \begin{aligncustom}
    \mathcal{N}(x|\mu,\sigma) &:= \frac{1}{\sqrt{2\pi\sigma^2}}\exp \left\{ \frac{-(x-\mu)^2}{2\sigma^2} \right\} \\~\\
    \ln \left( \mathcal{N}(x|\mu,\sigma) \right) &= \ln \left( \frac{1}{\sqrt{2\pi\sigma^2}}\exp \left\{ \frac{-(x-\mu)^2}{2\sigma^2} \right\} \right) \\~\\
    &= \ln \left( \frac{1}{\sqrt{2\pi\sigma^2}} \right) + \ln \left( \exp \left\{ \frac{-(x-\mu)^2}{2\sigma^2} \right\} \right) \\~\\
    &= \ln \left( \frac{1}{\sqrt{2\pi\sigma^2}} \right) + \frac{-(x-\mu)^2}{2\sigma^2}
  \end{aligncustom}

  The derivative can be applied and set to~$0$ as shown in Eq.~\eqref{eq:derivativeGaussian}.
  
  \begin{equation}
    0 = \frac{d}{dx} \ln \left( \mathcal{N}(x|\mu,\sigma) \right) = 0 - \frac{2(x-\mu)}{2\sigma^2}
    \label{eq:derivativeGaussian} 
  \end{equation}
  
  Eq.~\eqref{eq:derivativeGaussian} can be simplified yielding the final result as shown in Eq.~\eqref{eq:univariateGaussianFinal}.
  
  \begin{equation}
    x = \mu ~~~\square
    \label{eq:univariateGaussianFinal}
  \end{equation}
  

  \begin{subproblem}
    Show the mode of the multivariate Gaussian distribution is given by~$\bm{\mu}$.
  \end{subproblem}
  
  The multivariate Gaussian distribution is shown in Eq.~\eqref{eq:multivariateGaussian}.  $\mathbf{x}$~is an $n$-dimensional input vector while $\bm{\mu}$~is the $n$-dimensional mean vector.  $\Sigma$~is the $n \times n$~covariance matrix.
    
  \begin{equation}
    \mathcal{N}(\mathbf{x} | \bm{\mu}, \Sigma) := \frac{1}{(2\pi)^{\frac{n}{2}} | \Sigma | ^ {1/2} } \exp\left\{-\frac{1}{2} \left(\mathbf{x}-\bm{\mu} \right)^{\textrm{T}}\Sigma^{-1}\left(\mathbf{x}-\bm{\mu}\right) \right\}
    \label{eq:multivariateGaussian}
  \end{equation}

  Similar to the technique used in part~(a), the maximizing (mode) value of a strictly positive function is also the maximizing value of the function's natural log.  Hence, Eq.~\eqref{eq:multivariateGaussian} becomes:
  
  \begin{align}
    \ln \mathcal{N}(\mathbf{x} | \bm{\mu}, \Sigma)  &= \ln \left( \frac{1}{(2\pi)^{\frac{n}{2}} | \Sigma | ^ {1/2} } \exp\left\{-\frac{1}{2} \left(\mathbf{x}-\bm{\mu} \right)^{\textrm{T}}\Sigma^{-1}\left(\mathbf{x}-\bm{\mu}\right) \right\} \right) \\[2em]
    &= \ln \left( \frac{1}{(2\pi)^{\frac{n}{2}}} \right) + \ln \left( \exp\left\{-\frac{1}{2} \left(\mathbf{x}-\bm{\mu} \right)^{\textrm{T}}\Sigma^{-1}\left(\mathbf{x}-\bm{\mu}\right) \right\} \right) \\[2em]
    &= \ln \left( \frac{1}{(2\pi)^{\frac{n}{2}}} \right) - \frac{1}{2} \left(\mathbf{x}-\bm{\mu} \right)^{\textrm{T}}\Sigma^{-1}\left(\mathbf{x}-\bm{\mu}\right)  \textrm{.}
    \label{eq:logMultivariateGaussian}
  \end{align}

  The gradient of an $n$-dimensional function,~$f(\mathbf{x})$, is an $n$-dimensional vector as defined in Eq.~\eqref{eq:gradientF}.
  
  \begin{equation}
    \nabla f(\mathbf{x}) = \left\langle \frac{\partial f}{\partial x_1}, ..., \frac{\partial f}{\partial x_n} \right\rangle
    \label{eq:gradientF}
  \end{equation}
  
  A multivariate function is maximized when its gradient equals the zero vector~(i.e.,~$\mathbf{0}$).  Hence, take the derivative of Eq.~\eqref{eq:logMultivariateGaussian} and set it equal to the zero vector, which yields Eq.~\eqref{eq:partialMultivarGaussian}.
  
  \begin{align}
    \mathbf{0} = \frac{\partial}{\partial \mathbf{x}} \mathcal{N}(\mathbf{x} | \bm{\mu}, \Sigma) &= \mathbf{0} + \frac{\partial}{\partial \mathbf{x}} \left(\mathbf{x}-\bm{\mu} \right)^{\textrm{T}}\Sigma^{-1}\left(\mathbf{x}-\bm{\mu}\right)\\[1em]
    \mathbf{0} &= \frac{\partial}{\partial \mathbf{x}} \left(\mathbf{x}-\bm{\mu} \right)^{\textrm{T}}\Sigma^{-1}\left(\mathbf{x}-\bm{\mu}\right)
    \label{eq:partialMultivarGaussian}
  \end{align}
  
  If~$\mathbf{y} = \mathbf{x}-\bm{\mu}$ and~$A=\Sigma^{-1}$, then Eq.~\eqref{eq:partialMultivarGaussian} becomes:
  
  \begin{equation}
    \mathbf{0} = \frac{\partial}{\partial \mathbf{y}} \mathbf{y}^{\textrm{T}} A \mathbf{y}
    \label{eq:substituteMatrixProd}
  \end{equation}

  This matches the well known derivative identity that:
  
  \[ \frac{\partial}{\partial \mathbf{y}} \mathbf{y}^{\textrm{T}} A \mathbf{y} = (A^{\textrm{T}} + A)y \textrm{.}\]
    
  Hence, Eq.~\eqref{eq:substituteMatrixProd} simplifies to:
  
  \[ \mathbf{0} = (A^{\textrm{T}} + A)\mathbf{y} \textrm{.} \]

  Substituting back in for~$\mathbf{y}$ completes the proof via:
  
  \begin{aligncustom}
    (A^{\textrm{T}} + A)(\mathbf{x} - \bm{\mu}) &= \mathbf{0} \\~\\
    \mathbf{x} - \bm{\mu} &= \mathbf{0} \\~\\
    \mathbf{x} &= \bm{\mu} \textrm{.} ~~~\square
  \end{aligncustom}

  %---------------------------------------------------%
  \newpage
  \begin{problem}{1}{11}
    By setting the derivatives of the log likelihood function~(1.54) with respect to~$\mu$ and $\sigma^2$ equal to zero, verify the results~(1.55) and~(1.56).
  \end{problem}
  
  The log likelihood function~(Equation~1.54) is defined on page~27 as:
  
  \begin{equation}
    \ln p(\textbf{x}|\mu,\sigma^2)=-\frac{1}{2\sigma^2}\sum_{n=1}^{N}(x_{n}-\mu)^2-\frac{N}{2} \ln \sigma^2 -\frac{N}{2} \ln (2\pi)
  \end{equation}
  
  \begin{subproblem}
    Verify Equation~(1.55) that:
      \[ \mu_{ML} = \frac{1}{N}\sum_{n=1}^{N}x_{n} \]
  \end{subproblem}

  Take the partial derivative with respect to~$\mu$:
  
  \begin{aligncustom}
    \frac{\partial}{\partial \mu} \left( -\frac{1}{2\sigma^2}\sum_{n=1}^{N}(x_{n}-\mu)^2-\frac{N}{2} \ln \sigma^2 -\frac{N}{2} \ln (2\pi) \right) &= \frac{-1}{2\sigma^2}\left( 2 * -1 * \sum_{n=1}^{N}(x_{n}-\mu) \right)  - 0 - 0 \\
    &= \frac{\sum_{n=1}^{N}(x_{n}-\mu)}{\sigma^2} \\
    &= \frac{\sum_{n=1}^{N} \left( x_{n} \right)}{\sigma^2} - \frac{N*\mu}{\sigma^2}\textrm{.}
  \end{aligncustom}

  The right side of the equation can be set equal to~$0$.  The denominator can be multiplied out resulting in:
  
  \begin{aligncustom}
    0 &= \sum_{n=1}^{N} \left( x_{n} \right) - N*\mu \\
    N*\mu &= \sum_{n=1}^{N}x_{n} \\
    \mu &= \frac{1}{N}\sum_{n=1}^{N}x_{n} ~~~\square
  \end{aligncustom}


  \begin{subproblem}
    Verify Equation~(1.56) that:
    \[ \sigma_{ML}^2 = \frac{1}{N}\sum_{n=1}^{N} \left( x_{n} - \mu_{ML} \right)^{2} \]
  \end{subproblem}

  Taking the partial derivative with respect to~$\sigma$ and using the chain rule as necessary, we get:

  \begin{aligncustom}
    \frac{\partial}{\partial \sigma} \left( -\frac{1}{2\sigma^2}\sum_{n=1}^{N}(x_{n}-\mu)^{2}-\frac{N}{2} \ln \sigma^2 -\frac{N}{2} \ln (2\pi) \right) &=   -\frac{1}{2}\sum_{n=1}^{N}(x_{n}-\mu)^{2} * (-2*\sigma^{-3})  -\frac{N}{2} \left( \frac{1}{\sigma^2} (2\sigma)  \right)  - 0 \\
     &= \frac{\sum_{n=1}^{N}(x_{n}-\mu)^{2}}{\sigma^{3}} -\frac{N}{\sigma}
  \end{aligncustom}

  This equation is set equal to~$0$ and everything multiplied by~$\sigma$ resulting in:
  
  \begin{aligncustom}
    0 &= \frac{\sum_{n=1}^{N}(x_{n}-\mu)^{2}}{\sigma^{2}} - N \\
    N &= \frac{\sum_{n=1}^{N}(x_{n}-\mu)^{2}}{\sigma^{2}} \\
    \sigma^{2} &= \frac{\sum_{n=1}^{N}(x_{n}-\mu)^{2}}{N} \textrm{.}
  \end{aligncustom}

  The optimal value for~$\mu$ was found in part~(a) which can then be substituted into the previous equation yielding:
  
  \begin{aligncustom}
    \sigma^{2} &= \frac{\sum_{n=1}^{N}(x_{n}-\mu_{ML})^{2}}{N} \textrm{.} ~~~\square
  \end{aligncustom}


  %---------------------------------------------------%
  \newpage
  \begin{problem}{1}{29}
    Consider an $M$-state discrete random variable,~$x$, and use Jensen's inequality in the form~(1.115) to show that the entropy of its distribution~$p(x)$ satisfies~$\textrm{H}[x] \leq \ln M$.
  \end{problem}
  
  Equation~(1.115) in the textbook (page~56) states, that if the function $f$ is \textbf{convex}, then it holds that:
  
  \begin{equation}
    f \left( \sum_{i=1}^M{\lambda_{i} x_i} \right) \leq \sum_{i=1}^M{\lambda_{i} f(x_i)} \textrm{.}\label{eq:jensenConvex}
  \end{equation}
  
  However, if $f$ is \textbf{concave}, then the inequality is reversed meaning:
  
  \begin{equation}
    f \left( \sum_{i=1}^M{\lambda_{i} x_i} \right) \geq \sum_{i=1}^M{\lambda_{i} f(x_i)} \textrm{.}\label{eq:jensenConcave}
  \end{equation}
  
  Hence, given a probability distribution~$p(x)$, the entropy~$\mathbf{H}[x]$ is defined as:
  
  \begin{equation}
    \mathbf{H}[x] = -\sum_{i=1}^{M} p(x_i) \ln p(x_i) = \sum_{i=1}^{M} p(x_i) \ln \frac{1}{p(x_i)}
    \label{eq:preJensenEntropy}
  \end{equation}
    
  A probability distribution,~$p(x)$, satisfies the two Jensen Inequality criteria of~$\lambda$ namely:~$\forall_{i}\lambda_i \geq 0$ and~$\sum_{i=1}^{M}\left( \lambda_i \right) = 1$.  Similar consider~$f$ to be~$\ln$ and define~$x$ as:
  
  \[ x_{i} = \frac{1}{p(x_i)} \textrm{.} \]
  
  Therefore, Eq.~\eqref{eq:preJensenEntropy} is in a form where it may appear that Eq.~\eqref{eq:jensenConvex} would be applied.  However, logarithms are concave functions.  Hence, use Eq.~\eqref{eq:jensenConcave}, yielding:

  \begin{aligncustom}
    \ln \left( \sum_{i=1}^M p(x_i) \frac{1}{p(x_i)} \right) &\geq \sum_{i=1}^{M} p(x_i) \ln \frac{1}{p(x_i)} = \mathbf{H}[x] \\~\\
    \ln \left( \sum_{i=1}^M 1 \right) &\geq \mathbf{H}[x] \\~\\
    \ln M &\geq \mathbf{H}[x] \textrm{.}~~~\square
  \end{aligncustom}
 

  %---------------------------------------------------%
  \newpage
  \begin{problem}{1}{30}
    Evaluate the Kullback-Leibler divergence~(1.113) between two Gaussians,~$p(x)=\mathcal{N}(x|\mu,\sigma^2)$ and~$q(x)=\mathcal{N}(x|m,s^2)$.
  \end{problem}

  For two continuous probability distributions,~$p$ and~$q$, the Kullback-Leibler divergence is defined as:
  
  \[ {\KL(p||q) := \int p(x) \ln \frac{p(x)}{q(x)}} dx \textrm{.}\]
  
  Let's simplify the logarithm first.  Substituting for~$p(x)$ and~$q(x)$ yields:
  
  \begin{aligncustom}
    \ln \left( \frac{p(x)}{q(x)} \right) &= \ln \left(  \frac{ \frac{1}{\sqrt{2 \pi \sigma^2}} \exp \left( {-\frac{(x-\mu)^2}{2\sigma^2}} \right) } { \frac{1}{\sqrt{2 \pi s^2}} \exp \left( {-\frac{(x-m)^2}{2s^2}} \right) }  \right) \\~\\
    &=  \ln \left( \frac{s}{\sigma} \exp \left( -\frac{(x-\mu)^2}{2\sigma^2} + \frac{(x-m)^2}{2s^2} \right) \right) \\~\\
    &=  \ln \left( \frac{s}{\sigma} \right) + \ln \left( \exp \left( -\frac{(x-\mu)^2}{2\sigma^2} + \frac{(x-m)^2}{2s^2} \right) \right) \\~\\
    &=  \ln \left( \frac{s}{\sigma} \right) - \frac{(x-\mu)^2}{2\sigma^2} + \frac{(x-m)^2}{2s^2} \textrm{.}
  \end{aligncustom}

  Substituting this back into the original equation yields:
  
  \[ \KL(p||q) = \int p(x) \left( \ln \left( \frac{s}{\sigma} \right) - \frac{(x-\mu)^2}{2\sigma^2} + \frac{(x-m)^2}{2s^2} \right) dx \textrm{.} \]
  
  Expand the equation for simplification.  
  
  \begin{equation}
    \KL(p||q) = \int p(x) \ln \left( \frac{s}{\sigma} \right) - p(x) \frac{(x^2 - 2 \cdot x \cdot \mu + \mu^2)}{2\sigma^2} + p(x)  \frac{(x^2 -2 \cdot x \cdot m + m^2)}{2s^2} dx \textrm{.}
    \label{eq:expandedKL}
  \end{equation}
  
  Given~$p(x)=\mathcal{N}(x|\mu,\sigma^2)$ and a constant~$c$, a few useful identities are in Eq.~\eqref{eq:intPdf}, \eqref{eq:intExpectation},~and~\eqref{eq:intXsquared}.
  
  \begin{align}
    \int c \cdot p(x) dx &= c \label{eq:intPdf}\\[1em]
    \int c \cdot x \cdot p(x) dx &= c \cdot \mu \label{eq:intExpectation}\\[1em]
    \int c \cdot x^2 \cdot p(x) dx &= c \cdot \mu^2 + c \cdot \sigma^2 \label{eq:intXsquared}
  \end{align}
  
  Using these identities, Eq.~\eqref{eq:expandedKL} simplifies to:
  
  \begin{aligncustom}
    \KL(p||q) &= \ln \left( \frac{s}{\sigma} \right) - \frac{(\mu^2 + \sigma^2 - 2 \cdot \mu^2 + \mu^2)}{2\sigma^2} + \frac{(\mu^2 + \sigma^2 -2 \cdot \mu \cdot m + m^2)}{2s^2} \\~\\
    &= \ln \left( \frac{s}{\sigma} \right) - \frac{1}{2} + \frac{\sigma^2 + (\mu - m) ^ 2 }{2s^2}
  \end{aligncustom}

  If desired, the fraction can be pulled out resulting in the final form in Eq.~\eqref{eq:finalKL}.
  
  \begin{equation}
    \KL(p||q) = \frac{1}{2} \left( \ln \left( \frac{s^2}{\sigma^2} \right) - 1 + \frac{\sigma^2 + (\mu - m) ^ 2 }{s^2} \right)
    \label{eq:finalKL}
  \end{equation}

  
  %---------------------------------------------------%
  \newpage
  \begin{problem}{1}{31}
    Consider two variables~$\mathbf{x}$ and~$\mathbf{y}$ having joint distribution~$p(\mathbf{x},\mathbf{y})$, show that the differential entropy of this pair of variables satisfies
    \[\textrm{H}[\mathbf{x},\mathbf{y}] \leq \textrm{H}[\mathbf{x}] + \textrm{H}[\mathbf{y}]\]
    with equality if and only if~$\mathbf{x}$ and~$\mathbf{y}$ are statistically independent.
  \end{problem}

  The joint entropy of two variables can be written in terms of their marginal entropies of and their mutual information,~$\mathbf{I}[\mathbf{x},\mathbf{y}]$.  This is shown in Eq.~\eqref{eq:jointEntropyWithMutual}.
  
  \begin{equation}
    \textrm{H}[\mathbf{x},\mathbf{y}] = \textrm{H}[\mathbf{x}] + \textrm{H}[\mathbf{y}] - \textrm{I}[\mathbf{x};\mathbf{y}] \textrm{.}
    \label{eq:jointEntropyWithMutual}
  \end{equation}
  
  Cover \&~Thomas show that mutual information has the relationship:
  
  \begin{equation}
    \mathbf{I}[\mathbf{x},\mathbf{y}] \geq 0
    \label{eq:mutualInformationGreater0}
  \end{equation}
  
  \noindent
  with equality only in the case that~$\mathbf{x}$ and~$\mathbf{y}$ are independent~(see (2.90)~on page~28 of the second edition of Cover \&~Thomas).  Given Eq.~\eqref{eq:mutualInformationGreater0} and mutual information's non-negativity, it is clear that:
  
  \[ \textrm{H}[\mathbf{x}] + \textrm{H}[\mathbf{y}] - \textrm{I}[\mathbf{x};\mathbf{y}] \leq \textrm{H}[\mathbf{x}] + \textrm{H}[\mathbf{y}] \textrm{.} \]
  
  This in turn can be combined with Eq.~\eqref{eq:jointEntropyWithMutual} yielding:
  
  \begin{equation}
    \textrm{H}[\mathbf{x},\mathbf{y}] \leq \textrm{H}[\mathbf{x}] + \textrm{H}[\mathbf{y}] \textrm{.}
  \end{equation}
  
  Equality holds when~$\mathbf{I}[\mathbf{x};\mathbf{y}]=0$, which only occurs when~$\mathbf{X}$ and~$\mathbf{Y}$ are independent per Cover \&~Thomas.~~~$\square$
  
  %---------------------------------------------------%
  \newpage
  \begin{problem}{1}{40}
     By applying Jensen's inequality~(1.115) with~$f(x)=\ln x$, show that the arithmetic mean of a set of real numbers is never less than their geometrical mean.
  \end{problem}
  
  For a set of numbers,~$\{x_1,...,x_M\}$, the arithmetic mean is defined as:
  
  \[ \frac{\sum_{i=1}^{M}x_i}{M} \textrm{.} \]
  
  In contrast, for the same set of numbers, the geometric mean is defined as:
  
  \[ \left( \prod_{i=1}^{M}x_i \right)^\frac{1}{M}\textrm{.} \]
  
  Jensen's Inequality~(1.115) is defined as:
  
  \[ f \left( \sum_{i=1}^M{\lambda_{i} x_i} \right) \leq \sum_{i=1}^M{\lambda_{i} f(x_i)}\textrm{.}\]
  
  If we substitute for~$f(x)=\ln x$, the inequality becomes:

  \[ \ln \left( \sum_{i=1}^M{\lambda_{i} x_i} \right) \leq \sum_{i=1}^M{\lambda_{i} \ln(x_i)}\textrm{.} \]
  
  For Jensen's Inequality to hold, $\lambda$~must satisfy two conditions namely:~$\lambda_i \geq 0$ and~$\sum_{i=1}^{M}\left( \lambda_i \right) = 1$.  An obvious satisfying case is~$\lambda_i=1/M$ for all~$i=1...M$.  This then changes the equation to:
  
  \[ \ln \left( \frac{\sum_{i=1}^{M}{x_i}}{M} \right) \leq \frac{1}{M}\sum_{i=1}^M{\ln(x_i)}\textrm{.} \]
  
  Using the properties of logarithms, the right side is transformable to a product via:
  
  \[ \ln \left( \frac{\sum_{i=1}^{M}{x_i}}{M} \right) \leq \frac{1}{M}{\ln \left( \prod_{i=1}^M{x_i} \right)}\textrm{.} \]
  
  Using another property of logarithms, the multiplying scalar,~$\frac{1}{M}$ can be brought inside the logarithm as:
  
  \[ \ln \left( \frac{\sum_{i=1}^{M}{x_i}}{M} \right) \leq \ln \left( \left( \prod_{i=1}^M{x_i}\right)^\frac{1}{M} \right) \textrm{.} \]
  
  Both sides are then raised to the power of~$e$ completing the proof.
  
  \[ \frac{\sum_{i=1}^{M}{x_i}}{M} \leq \left( \prod_{i=1}^M{x_i}\right)^\frac{1}{M}  ~~~\square \]

  %---------------------------------------------------%
  \newpage
  \begin{extraproblem}
    Prove that the sum of two convex functions is also convex.
  \end{extraproblem} 
   
  A function,~$f(x)$, is convex over an interval~$(a,b)$ if for every ${x_{1},x_{2} \in (a,b)}$ and ${0 \leq \lambda \leq 1}$,
  
  \begin{equation}
    f\left(\lambda x_{1} + (1-\lambda) x_{2} \right) \leq \lambda f(x_{1}) + (1-\lambda) f(x_{2}) \textrm{.}
  \end{equation}

  Given a second convex function,~$g(x)$, and an additional function,~$h(x)=f(x)+g(x)$, add the definition of convexity for~$f$ to the definition of convexity for~$g$ as shown in Eq.~\eqref{eq:convexEquation}.
  
  \begin{equation}
    f(\lambda x_{1} + (1-\lambda) x_{2}) + g(\lambda x_{1} + (1-\lambda) x_{2}) \leq \lambda f(x_{1}) + (1-\lambda) f(x_{2}) + \lambda g(x_{1}) + (1-\lambda) g(x_{2}) \textrm{.}
    \label{eq:convexEquation}
  \end{equation}
  
  This can be rearranged due to the associativity and commutativity of real valued addition.
  
  \[(f(\lambda x_{1} + (1-\lambda) x_{2}) + g(\lambda x_{1} + (1-\lambda) x_{2})) \leq \lambda (f(x_{1}) ) + g(x_{1})) + (1-\lambda) (f(x_{2}) + g(x_{2})) \textrm{.}\]

  Substituting using the definition of~$h(x)$ proves convexity via:
  
  \[ h(\lambda x_{1} + (1-\lambda) x_{2}) \leq \lambda h(x_{1}) + (1-\lambda) h(x_{2}) \textrm{.} ~~~\square \]

\end{document}